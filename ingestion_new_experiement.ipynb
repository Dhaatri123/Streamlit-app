{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO3LWEH7ouwJHxX5bbPwEB8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9ZrW-GQkXG4E","executionInfo":{"status":"ok","timestamp":1731321272991,"user_tz":-330,"elapsed":9726,"user":{"displayName":"Dhaatri Prasanna","userId":"13940518972722042632"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d0418fe5-a8ef-43f9-a8d4-a7c0a2e70c51"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n","Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.25.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.19.2)\n","Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.4.1)\n","Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.2)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.32.3)\n","Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (24.1)\n","Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.8.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.65.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (3.20.3)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.25.0)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.64.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.48.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n","Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.8.30)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.6.1)\n"]}],"source":["!pip install google-cloud-storage google-cloud-bigquery pandas\n"]},{"cell_type":"code","source":["from google.colab import auth\n","auth.authenticate_user()"],"metadata":{"id":"wSbPq53FykyN","executionInfo":{"status":"ok","timestamp":1731405743738,"user_tz":-330,"elapsed":74899,"user":{"displayName":"Dhaatri Prasanna","userId":"13940518972722042632"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["\n","\n","PROJECT_ID = 'maximal-chemist-355505'\n","!gcloud config set project $PROJECT_ID"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3Qj_VHwymDg","executionInfo":{"status":"ok","timestamp":1731405750481,"user_tz":-330,"elapsed":2143,"user":{"displayName":"Dhaatri Prasanna","userId":"13940518972722042632"}},"outputId":"bb234cf5-4bf0-47eb-ba47-ba68a2ceff74"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Updated property [core/project].\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from google.cloud import bigquery, storage\n","import os\n","from io import BytesIO\n","\n","# Set up GCS and BigQuery details\n","GCS_BUCKET_NAME = 'hdfc_segmentwise_data'\n","PROJECT_ID = 'maximal-chemist-355505'\n","BIGQUERY_DATASET = 'hdfc_dummy'\n","\n","# Initialize Google Cloud Storage and BigQuery clients\n","storage_client = storage.Client(project=PROJECT_ID)\n","bq_client = bigquery.Client(project=PROJECT_ID)\n","\n","def sanitize_column_names(df):\n","    \"\"\"\n","    Sanitizes DataFrame column names to comply with BigQuery standards\n","    and applies specific transformations based on known column names.\n","    \"\"\"\n","    df.columns = df.columns.str.replace(' ', '_').str.lower()\n","    df.columns = df.columns.str.replace(r\"[^a-z0-9_]\", \"_\", regex=True).str.replace(r\"_+\", \"_\", regex=True).str.strip('_')\n","    column_mapping = {\n","        'Fire': 'fire',\n","        'Marine Total': 'marine_total',\n","        'Marine Cargo': 'marine_cargo',\n","        'Marine Hull': 'marine_hull',\n","        'Engineering': 'engineering',\n","        'Motor Total': 'motor_total',\n","        'Motor OD': 'motor_od',\n","        'Motor TP': 'motor_tp',\n","        'Health': 'health',\n","        'Aviation': 'aviation',\n","        'P.A': 'personal_accident',\n","        'All Other Misc (Crop Insurance+ Credit guarantee + All Other Misc)': 'all_other_misc',\n","        'Grand Total': 'grand_total',\n","        'Growth %': 'growth_percentage',\n","        'Market %': 'market_percentage',\n","        'Accretion': 'accretion'\n","    }\n","    df.rename(columns=column_mapping, inplace=True)\n","    return df\n","\n","def handle_previous_year_and_growth_rows(df):\n","    \"\"\"\n","    Processes rows with 'Previous Year' and '% Growth' indicators to append relevant names.\n","    Ignores any rows after 'Previous Year Market Share' that contain irrelevant text or special characters.\n","    \"\"\"\n","    processed_data = []\n","    skip_rows = False\n","    for i in range(len(df)):\n","        row = df.iloc[i]\n","        if \"Previous Year Market Share\" in row.values:\n","            skip_rows = True\n","            continue\n","        if skip_rows:\n","            continue\n","        if row.str.contains(\"^Previous Year$\", case=False, regex=True).all():\n","            if i - 1 >= 0:\n","                prev_name = df.iloc[i - 1].astype(str).str.cat(sep=' ').strip() + \"_Previous Year\"\n","                row = row.copy()\n","                row[:] = prev_name\n","            processed_data.append(row)\n","        elif row.str.contains(r\"^% Growth$\", case=False, regex=True).all():\n","            if i - 2 >= 0:\n","                growth_name = df.iloc[i - 2].astype(str).str.cat(sep=' ').strip() + \"_Growth\"\n","                row = row.copy()\n","                row[:] = growth_name\n","            processed_data.append(row)\n","        else:\n","            processed_data.append(row)\n","    df_processed = pd.DataFrame(processed_data, columns=df.columns)\n","    return df_processed\n","\n","def convert_column_types(df):\n","    \"\"\"\n","    Converts DataFrame column types to ensure compatibility with BigQuery.\n","    \"\"\"\n","    for column in df.columns:\n","        df[column] = df[column].astype(str)\n","    return df\n","\n","def find_segmentwise_sheet(excel_data):\n","    \"\"\"\n","    Finds the correct sheet containing 'segmentwise' in its name or specific columns.\n","    \"\"\"\n","    xls = pd.ExcelFile(BytesIO(excel_data))\n","    sheet_name = None\n","    for name in xls.sheet_names:\n","        if \"segmentwise\" in name.lower():\n","            print(f\"Found sheet with 'segmentwise' in name: {name}\")\n","            sheet_name = name\n","            break\n","    if sheet_name is None:\n","        known_columns = ['fire', 'marine_total', 'marine_cargo', 'health']\n","        for sheet_index in [2, 3]:\n","            if sheet_index < len(xls.sheet_names):\n","                temp_df = pd.read_excel(xls, sheet_name=sheet_index, header=1)\n","                temp_df.columns = temp_df.columns.str.lower().str.replace(' ', '_').str.replace(r\"[^a-z0-9_]\", \"_\", regex=True)\n","                if all(col in temp_df.columns for col in known_columns):\n","                    print(f\"Found sheet with known columns at index {sheet_index}: {xls.sheet_names[sheet_index]}\")\n","                    sheet_name = xls.sheet_names[sheet_index]\n","                    break\n","    return sheet_name\n","\n","def check_table_exists(table_id):\n","    \"\"\"\n","    Checks if a table exists in BigQuery.\n","    \"\"\"\n","    try:\n","        bq_client.get_table(table_id)\n","        return True\n","    except:\n","        return False\n","\n","def load_excel_files_to_bigquery(request):\n","    request_json = request.get_json()\n","    if request.args and 'message' in request.args:\n","        return request.args.get('message')\n","    else:\n","        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n","        blobs = bucket.list_blobs(prefix='comp-segmentwise/')\n","        excel_files = [blob.name for blob in blobs if blob.name.endswith('.xlsx')]\n","\n","        if not excel_files:\n","            print(\"No Excel files found in the specified GCS bucket.\")\n","            return 'No Excel files found.'\n","\n","        for file_path in excel_files:\n","            file_name = os.path.basename(file_path).replace('.xlsx', '').replace('-', '_')\n","            table_id = f'{PROJECT_ID}.{BIGQUERY_DATASET}.{file_name}'\n","\n","            if check_table_exists(table_id):\n","                print(f\"Table {table_id} already exists. Skipping table creation.\")\n","                continue\n","\n","            print(f'Processing {file_path} and creating table {file_name}')\n","            blob = bucket.blob(file_path)\n","            excel_data = blob.download_as_bytes()\n","\n","            sheet_name = find_segmentwise_sheet(excel_data)\n","            if sheet_name is None:\n","                print(f'No relevant sheet found in {file_path}. Skipping this file.')\n","                continue\n","\n","            df = pd.read_excel(BytesIO(excel_data), header=2, sheet_name=sheet_name)\n","            df = sanitize_column_names(df)\n","            df = handle_previous_year_and_growth_rows(df)\n","            df = convert_column_types(df)\n","\n","            job_config = bigquery.LoadJobConfig(\n","                write_disposition=bigquery.WriteDisposition.WRITE_EMPTY,  # Only create the table if it doesn't exist\n","                autodetect=True\n","            )\n","\n","            try:\n","                job = bq_client.load_table_from_dataframe(df, table_id, job_config=job_config)\n","                job.result()\n","                table = bq_client.get_table(table_id)\n","                print(f'Loaded {table.num_rows} rows into table {table_id}.')\n","            except Exception as e:\n","                print(f'Error loading table {table_id}: {e}')\n","\n","        return 'Task successfully completed'\n"],"metadata":{"id":"RR-Zeeqvzcqu","executionInfo":{"status":"ok","timestamp":1731406211617,"user_tz":-330,"elapsed":434,"user":{"displayName":"Dhaatri Prasanna","userId":"13940518972722042632"}}},"execution_count":4,"outputs":[]}]}